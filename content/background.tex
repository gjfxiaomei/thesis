% 本文件是示例论文的一部分
% 论文的主文件位于上级目录的 `bachelor.tex` 或 `master.tex`

\chapter{背景和研究意义}
\section{研究背景}
交通信号控制是一个重要且具有挑战性的现实问题，其目标是最大化车辆的通行效率通过协调他们在交叉路口的行动。随着汽车制造业的快速发展以及城市化进程的推进，我国汽车保有量在不断的增加，交通拥堵情况也在不断恶化，极大的影响了人们的生活的城市的运作，同时这种拥堵现象也在向中小城市蔓延。为了缓解交通拥堵，很多城市也提出了不同的解决方法，有减少出行车辆数量的“限号”政策，也有通过加快城市道路建设来加大城市交通承载量的方法。其实，交通拥堵通常是由于不同的车流为了争夺同一个“行驶资源”而造成的。这一“行驶资源”通常就是不同道路的交叉口，所以现代城市交通管理中在道路的交叉口安装信号灯并通过简单的策略来调度通过的车流。但是随着车辆数量的不断增加，之前简单的策略已经难以应对现在更加复杂的交通模式。因此，如何制定出更加高效和智能的调度策略显得格外的重要。

智能交通信号控制会根据实时的交通状况做出最优的决策并以此来控制信号灯的变化，已达到最大程度地减轻交通拥堵的目的。传统的交通控制更多的是基于一些既定的规则和一些根据历史数据总结出的经验来控制信号灯，没有考虑实时的交通状况，所以无法很有效的减轻交通拥堵的状况，但是由于其简单以及易于部署的特点，绝大多数城市的信号灯都还在采用这种控制模式。

随着车联网技术的发展，对于实时车辆数据的获取变得越来越容易，利用得到的车辆数据可以获得实时的交通状况，并且如何根据实时的交通状况来制定最优的策略一直是研究的热点。以往多数的研究是采用基于优化的方法，根据车流的状况计算出一个最优的信号灯的相位序列，但是这种方法要求车流的状况是比较简单的，例如服从均匀分布，与现实中的车流情况相比太过理想化，所以难以部署到实际场景中。伴随着人工智能技术的发展，一些研究者提出利用深度强化学习来控制信号灯，将整个交通信号灯控制建模成一个马尔可夫决策过程（Markov Decision Process）。对于每一次决策，输入当前的交通状况作为状态，输出一个作用在信号灯上的动作，例如变换到下一个相位（phase）。这种方法对于车流的情况没有限制，通过在大量不同的车流状况下进行训练可以得到一个鲁棒的模型，能够应对不同的车流场景并做出最优的决策，并且这种方法在通行效率上也比基于优化的方法和传统的规则控制方法更高。

但是在多数已有的工作中，都是使用车辆的平均行驶时间来量化通行效率，这就会导致一个公平失衡的问题。控制策略在控制信号灯的时候会更加倾向于放行有更多等待车辆的车道（主干道），所以在拥有较少车辆车道（次干道）上的车可能很长时间得不到放行，这对于次干道上的车来说是不公平的。因此如何设计出在最大化通行效率的同时又能保障所有车辆相对公平的策略具有重要的意义。

\section{国内外研究现状}
目前，已有的关于交通信号控制的研究主要可以分为两大类，一类是传统的交通信号控制，另一种是基于学习的交通信号控制。

传统交通信号控制可以细分为两类：第一类是基于预定义的信号控制（pre-defined signal control）[5]，根据历史交通流量信息预先定义信号的序列和周期。由于没有考虑到实时交通的情况，所以不能够有效地适应动态的交通变化。第二类是基于优化方法的自适应控制，这些方法通常是从优化的角度解决某些交通流模型下的交通信号控制问题，并且根据观测到的数据调整信号的序列和周期。然而，为了让问题易于求解，通常在模型上做出很强的假设[6]-[8]。例如，为了优化车辆通行时间，Webster在工作[9]中假设车辆的到达率是均匀的。这些假设通常太过理想化，不适用于现实世界。
与传统交通信号控制不同的是，基于学习的交通信号控制不需要预先定义的规则和不切实际的假设。具体来说，这类方法直接从与环境的交互中学习，并且根据环境的反馈来完善和改进控制策略，逐渐达到最优的效果。现有的基于学习的信号控制方法的差异主要表现在三个方面：状态表示，奖励设计和学习算法。交通状态可以使用不同的特征来描述，例如等待车辆的队列长度[1], [10], [11]、平均延迟[12], [13]以及车辆的位置影像[10], [14]。通常，几个特征被整合起来，以获得对交通状况的全面描述。奖励通常是根据等待时间[13], [15], [16],队列长度[2], [11]和吞吐量[10], [17], [18]来设计的。学习算法一般可分为基于价值的方法[10], [13], [15]，基于策略的方法[19], [20]和基于Actor-Critic的方法[17], [21]。
然而，大多数现有的基于学习的方法只侧重于提高交叉口的效率，例如最小化队列长度或最大化吞吐量，而忽略了对公平性的考虑。 事实上，这样的目标可能导致学到一个有偏见的策略，控制策略会更加偏向于主干道上的车辆，可能会导致次干道上的车长时间得不到放行（这一情况被称为“饥饿”现象）。 另一方面，在最近一段时间，对于多路口交通信号控制的研究，使用分布式强化学习的独立控制方式逐渐取代以往的整体控制方式（对所有路口使用一个智能体来进行学习），不同智能体之间通过显示的通信来交流信息，从而实现协同控制。但是已有的工作对于通信过程中信息选择的研究却有所不足，目前常用的方式就是将智能体自己观测到的局部环境全部传输给相邻路口的智能体。虽然这种做法可以让智能体对全局环境有更加全面的了解，于此同时也增加了通信代价，而且还让智能体的训练难度加大。此外，并不是所有的信息对于其相邻的路口都是有用的，可能有些信息对其上游路口有用，有些影响其下游路口，为特定路口筛选特定的信息来进行交流不仅可以减少通信代价，而且可以让学习的效率提高。

